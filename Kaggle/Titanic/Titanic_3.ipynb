{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83223fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://velog.io/@hyungraelee/Titanic-Machine-Learning-from-Disaster-Pytorch\n",
    "import pandas as pd ##데이터를 처리하기 위한 pandas import\n",
    "import numpy as np ##행렬 연산에 능한 numpy를 선언한다.\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch ##pytorch의 핵심 라이브러리로, 텐서연산과 gradient연산을 수행한다.\n",
    "import torch.nn as nn ##딥러닝 모델을 설계하기 사용된다.\n",
    "import torch.nn.functional as F ##activation function과, loss function을 위해 사용된다.\n",
    "from torch.utils.data import TensorDataset ##pytorch의 데이터셋을 나누기 위해 사용된다.\n",
    "from torch.utils.data import DataLoader ##데이터를 미니 베치로 나누고, 로딩 및 셔플링을 관여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5990fcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"/Users/kwonmincheol/Documents/DeepLearning/Titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"/Users/kwonmincheol/Documents/DeepLearning/Titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36766f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info() ##데이터의 열의 정보를 확인한다. 또한 누락치를 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93ae0835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head() ##데이터를 재대로 읽었는지 확인하고, 대략적인 개요를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7bef6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info() ##테스트 데이터에 대한 정보를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8275b4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(['Name','Ticket','Cabin'], axis=1, inplace=True)\n",
    "test_data.drop(['Name','Ticket','Cabin'], axis=1, inplace=True)\n",
    "# inplace=True는 원본 데이터를 수정하겠다는것을 의미.\n",
    "##axis=1의 의미는 해당 열을 삭제하라는 의미이다. axis=0일경우 해당 행을 삭제한다\n",
    "##inplace=True를 통하여 복사본이 아닌 직접적으로 해당 데이터에서 직접적으로 처리하는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6524132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n",
       "0              1         0       3    male  22.0      1      0   7.2500   \n",
       "1              2         1       1  female  38.0      1      0  71.2833   \n",
       "2              3         1       3  female  26.0      0      0   7.9250   \n",
       "3              4         1       1  female  35.0      1      0  53.1000   \n",
       "4              5         0       3    male  35.0      0      0   8.0500   \n",
       "..           ...       ...     ...     ...   ...    ...    ...      ...   \n",
       "886          887         0       2    male  27.0      0      0  13.0000   \n",
       "887          888         1       1  female  19.0      0      0  30.0000   \n",
       "888          889         0       3  female   NaN      1      2  23.4500   \n",
       "889          890         1       1    male  26.0      0      0  30.0000   \n",
       "890          891         0       3    male  32.0      0      0   7.7500   \n",
       "\n",
       "    Embarked  \n",
       "0          S  \n",
       "1          C  \n",
       "2          S  \n",
       "3          S  \n",
       "4          S  \n",
       "..       ...  \n",
       "886        S  \n",
       "887        S  \n",
       "888        S  \n",
       "889        C  \n",
       "890        Q  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d6b8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(train_data['Sex'],drop_first=True)\n",
    "embark = pd.get_dummies(train_data['Embarked'], drop_first=True)\n",
    "# drop_first=True 는 첫번째 옵션을 drop함을 뜻합니다.\n",
    "# 예로 Sex column에서 female이 1이라면, 0인 row는 자동으로 male을 의미하게 됩니다.\n",
    "# drop first는 가장 앞의 항을 삭제하겠다는 것을 의미한다 따라서 여기서는 female항을 없애 male의 1 0 만으로 판별을 진행한다.\n",
    "##get dummies 를 이용하여 범주형 데이터를 변수로 변환한다. Sex의 경우 male 또는 female이 나오므로, femaledㅡㄹ 삭제하기 위해 drop_first 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9920878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch     Fare  \\\n",
       "0              1         0       3    male  22.0      1      0   7.2500   \n",
       "1              2         1       1  female  38.0      1      0  71.2833   \n",
       "2              3         1       3  female  26.0      0      0   7.9250   \n",
       "3              4         1       1  female  35.0      1      0  53.1000   \n",
       "4              5         0       3    male  35.0      0      0   8.0500   \n",
       "..           ...       ...     ...     ...   ...    ...    ...      ...   \n",
       "886          887         0       2    male  27.0      0      0  13.0000   \n",
       "887          888         1       1  female  19.0      0      0  30.0000   \n",
       "888          889         0       3  female   NaN      1      2  23.4500   \n",
       "889          890         1       1    male  26.0      0      0  30.0000   \n",
       "890          891         0       3    male  32.0      0      0   7.7500   \n",
       "\n",
       "    Embarked  male  Q  S  \n",
       "0          S     1  0  1  \n",
       "1          C     0  0  0  \n",
       "2          S     0  0  1  \n",
       "3          S     0  0  1  \n",
       "4          S     1  0  1  \n",
       "..       ...   ... .. ..  \n",
       "886        S     1  0  1  \n",
       "887        S     0  0  1  \n",
       "888        S     0  0  1  \n",
       "889        C     1  0  0  \n",
       "890        Q     1  1  0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.concat([train_data, sex, embark], axis=1)\n",
    "train_data\n",
    "#다음과 같이 진행하므로써 Q와 S가 생겨났다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b786599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  male  Q  S\n",
       "0              1         0       3  22.0      1      0   7.2500     1  0  1\n",
       "1              2         1       1  38.0      1      0  71.2833     0  0  0\n",
       "2              3         1       3  26.0      0      0   7.9250     0  0  1\n",
       "3              4         1       1  35.0      1      0  53.1000     0  0  1\n",
       "4              5         0       3  35.0      0      0   8.0500     1  0  1\n",
       "..           ...       ...     ...   ...    ...    ...      ...   ... .. ..\n",
       "886          887         0       2  27.0      0      0  13.0000     1  0  1\n",
       "887          888         1       1  19.0      0      0  30.0000     0  0  1\n",
       "888          889         0       3   NaN      1      2  23.4500     0  0  1\n",
       "889          890         1       1  26.0      0      0  30.0000     1  0  0\n",
       "890          891         0       3  32.0      0      0   7.7500     1  1  0\n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.drop(['Sex','Embarked'], axis=1, inplace=True)\n",
    "train_data\n",
    "##Sex 와 Embarked의 열을 삭제해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49d63b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = pd.get_dummies(test_data['Sex'], drop_first=True)\n",
    "embark = pd.get_dummies(test_data['Embarked'], drop_first=True)\n",
    "test_data = pd.concat([test_data, sex, embark], axis=1)\n",
    "test_data.drop(['Sex', 'Embarked'], axis=1, inplace=True)\n",
    "#테스트에도 동일한 과정을 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e71988d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.fillna(train_data.mean(), inplace=True) ##나머지 데이터들에 대해서 결측치를 채우는 과정을 진행한다.\n",
    "test_data.fillna(test_data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2ee886c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Age          891 non-null    float64\n",
      " 4   SibSp        891 non-null    int64  \n",
      " 5   Parch        891 non-null    int64  \n",
      " 6   Fare         891 non-null    float64\n",
      " 7   male         891 non-null    uint8  \n",
      " 8   Q            891 non-null    uint8  \n",
      " 9   S            891 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), uint8(3)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()\n",
    "##따라서 다음과 같이 모든 데이터가 non-NULL항목이 891개로 동일해진 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8af48d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['Survived'].values ##결과값에 해당하는 Survived열의 값을 추출하여 Numpy배열로 변환한다.\n",
    "sub_PassengerId = test_data['PassengerId'].values ##결과를 추출할때의 승객 식별차를 위해 저장한다.\n",
    "\n",
    "Scaler1 = StandardScaler()\n",
    "Scaler2 = StandardScaler()\n",
    "#StandardScaler을 이용하여 데이터를 정규화 해준다.\n",
    "\n",
    "train_columns = train_data.columns ##Train data의 열의 정보를 저장한다.\n",
    "test_columns = test_data.columns ##Test data의 열의 정보를 저장한다.\n",
    "\n",
    "train_data = pd.DataFrame(Scaler1.fit_transform(train_data)) ##train data를 정규화한다. 이후 data frame으로 변환하여 저장한다.\n",
    "test_data = pd.DataFrame(Scaler2.fit_transform(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f85ed50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730108</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726220</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.614710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.722332</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.718444</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.714556</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -1.730108 -0.789272  0.827377 -0.592481  0.432793 -0.473674 -0.502445   \n",
       "1 -1.726220  1.266990 -1.566107  0.638789  0.432793 -0.473674  0.786845   \n",
       "2 -1.722332  1.266990  0.827377 -0.284663 -0.474545 -0.473674 -0.488854   \n",
       "3 -1.718444  1.266990 -1.566107  0.407926  0.432793 -0.473674  0.420730   \n",
       "4 -1.714556 -0.789272  0.827377  0.407926 -0.474545 -0.473674 -0.486337   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.737695 -0.307562  0.619306  \n",
       "1 -1.355574 -0.307562 -1.614710  \n",
       "2 -1.355574 -0.307562  0.619306  \n",
       "3 -1.355574 -0.307562  0.619306  \n",
       "4  0.737695 -0.307562  0.619306  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf7d2dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730108</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726220</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.614710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.722332</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.718444</td>\n",
       "      <td>1.266990</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.714556</td>\n",
       "      <td>-0.789272</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.619306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "0    -1.730108 -0.789272  0.827377 -0.592481  0.432793 -0.473674 -0.502445   \n",
       "1    -1.726220  1.266990 -1.566107  0.638789  0.432793 -0.473674  0.786845   \n",
       "2    -1.722332  1.266990  0.827377 -0.284663 -0.474545 -0.473674 -0.488854   \n",
       "3    -1.718444  1.266990 -1.566107  0.407926  0.432793 -0.473674  0.420730   \n",
       "4    -1.714556 -0.789272  0.827377  0.407926 -0.474545 -0.473674 -0.486337   \n",
       "\n",
       "       male         Q         S  \n",
       "0  0.737695 -0.307562  0.619306  \n",
       "1 -1.355574 -0.307562 -1.614710  \n",
       "2 -1.355574 -0.307562  0.619306  \n",
       "3 -1.355574 -0.307562  0.619306  \n",
       "4  0.737695 -0.307562  0.619306  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns = train_columns ##다시 이전 열의 이름으로 바꾸어준다.\n",
    "test_data.columns = test_columns\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f762457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.iloc[:,2:].values\n",
    "##각각의 독립변수 특성을 나타내는 배열이다. 모든 행은 전부다 넣으며, 열의 정보는 2열부터 넣는다.\n",
    "##2열 부터 넣는 이유인 즉슨 PassengerId와 Surivived는 학습에 의미가 없기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d553614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82737724, -0.5924806 ,  0.43279337, ...,  0.73769513,\n",
       "        -0.30756234,  0.61930636],\n",
       "       [-1.56610693,  0.63878901,  0.43279337, ..., -1.35557354,\n",
       "        -0.30756234, -1.61470971],\n",
       "       [ 0.82737724, -0.2846632 , -0.4745452 , ..., -1.35557354,\n",
       "        -0.30756234,  0.61930636],\n",
       "       ...,\n",
       "       [ 0.82737724,  0.        ,  0.43279337, ..., -1.35557354,\n",
       "        -0.30756234,  0.61930636],\n",
       "       [-1.56610693, -0.2846632 , -0.4745452 , ...,  0.73769513,\n",
       "        -0.30756234, -1.61470971],\n",
       "       [ 0.82737724,  0.17706291, -0.4745452 , ...,  0.73769513,\n",
       "         3.25137334, -1.61470971]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa67b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (layer3): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module): ##딥러닝 모델을 올린다.\n",
    "    def __init__(self): ##생성자이다.\n",
    "        super(Net,self).__init__() ##nn.Module의 생성자를 호출한다.\n",
    "        self.layer1 = nn.Sequential( ##각 층의 연산을 순차적으로 진행한다.\n",
    "        nn.Linear(8, 512),\n",
    "        nn.ReLU(), ##활성화 함수를 이용하여 비선형성을 추가한다.\n",
    "        nn.Dropout(0.2)) ##\n",
    "        self.layer2 = nn.Sequential(\n",
    "        nn.Linear(512, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2))\n",
    "        self.layer3 = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "##다층 퍼셉트론 형태의 신경망을 정의하고 있다.\n",
    "##비선형성이 추가되어야 하는 이유로는 실제 문제는 비선형성이 존재해야지만 실제 문제를 해결할 수 있다.\n",
    "##또한 Drop out을 이용하여 훈련중에 일부 뉴런을 비활성화 하여 과적합을 방지하는데 사용된다. 이때 p는 비율을 나타낸다.\n",
    "##forward함수를 이용하여 순전파의 연산을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee1560e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train) ##pytorch에 학습을 시키기 위해서 FloatTensor으로 정의한다.\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "dataset = TensorDataset(X_train, y_train) ##학습 데이터와 레이블을 결합하여 데이터셋을 생성한다. 이후 데이터와 레이블 함께 관리 가능하다.\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "##매 epoch마다 데이터를 섞으며, batchsize를 64개로 한다.\n",
    "##batch size가 커지면 커질수록 전체 훈련 횟수가 감소하여 학습 시간이 짧아진다.\n",
    "##batch 의 크기가 매우 작다면 꼼꼼하게 살펴보며 학습이 진행되지만, 가중치 업데이터에서 최적화 탐색 경로를 크게 벗어날 수도 있다.\n",
    "##batch의 크기가 매우 크다면 훈련하는 횟수가 줄어든다. batch의 사이즈가 너무 클 경우에는 극소값에서 벗어나기가 어렵다.\n",
    "##https://otugi.tistory.com/350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "110e26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() ##크로스 엔프로피 손실 함수를 사용한다. 이 손실함수는 다중 클래스 분류문제에 적합하다.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) ##최적화 알고리즘을 따진다.\n",
    "##Adam최적화 알고리즘을 사용하여 모델의 가중치와 편향을 업데이트하는데 사용한다. Adam은 경사 하강법의 한 변종이다.\n",
    "##model.parameters()는 학습 가능한 매개변수를 모두 반환한다.\n",
    "##학습률을 0.01으로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9059600c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Prediction : 611/891, Cost : 0.8237580167993017\n",
      "=*=*=*= Loss decreased (   inf ===> 0.823758). Saving the model! =*=*=*=\n",
      "Epoch 2/500, Prediction : 725/891, Cost : 0.4404753931911974\n",
      "=*=*=*= Loss decreased (0.823758 ===> 0.440475). Saving the model! =*=*=*=\n",
      "Epoch 3/500, Prediction : 735/891, Cost : 0.42829549061730254\n",
      "=*=*=*= Loss decreased (0.440475 ===> 0.428295). Saving the model! =*=*=*=\n",
      "Epoch 4/500, Prediction : 745/891, Cost : 0.41748250410479193\n",
      "=*=*=*= Loss decreased (0.428295 ===> 0.417483). Saving the model! =*=*=*=\n",
      "Epoch 5/500, Prediction : 740/891, Cost : 0.406830166191632\n",
      "=*=*=*= Loss decreased (0.417483 ===> 0.406830). Saving the model! =*=*=*=\n",
      "Epoch 6/500, Prediction : 746/891, Cost : 0.4124830505663297\n",
      "Epoch 7/500, Prediction : 741/891, Cost : 0.39526329471339816\n",
      "=*=*=*= Loss decreased (0.406830 ===> 0.395263). Saving the model! =*=*=*=\n",
      "Epoch 8/500, Prediction : 749/891, Cost : 0.3821789199187432\n",
      "=*=*=*= Loss decreased (0.395263 ===> 0.382179). Saving the model! =*=*=*=\n",
      "Epoch 9/500, Prediction : 745/891, Cost : 0.38749790822148455\n",
      "Epoch 10/500, Prediction : 754/891, Cost : 0.39219469340428226\n",
      "Epoch 11/500, Prediction : 747/891, Cost : 0.3877849488212872\n",
      "Epoch 12/500, Prediction : 752/891, Cost : 0.38224344880358807\n",
      "Epoch 13/500, Prediction : 749/891, Cost : 0.3717357332323804\n",
      "=*=*=*= Loss decreased (0.382179 ===> 0.371736). Saving the model! =*=*=*=\n",
      "Epoch 14/500, Prediction : 749/891, Cost : 0.3897401264018884\n",
      "Epoch 15/500, Prediction : 743/891, Cost : 0.38571986321915946\n",
      "Epoch 16/500, Prediction : 743/891, Cost : 0.4203851490242848\n",
      "Epoch 17/500, Prediction : 736/891, Cost : 0.39435664913068313\n",
      "Epoch 18/500, Prediction : 749/891, Cost : 0.38062324678456344\n",
      "Epoch 19/500, Prediction : 756/891, Cost : 0.36878341202248893\n",
      "=*=*=*= Loss decreased (0.371736 ===> 0.368783). Saving the model! =*=*=*=\n",
      "Epoch 20/500, Prediction : 751/891, Cost : 0.37425136823713046\n",
      "Epoch 21/500, Prediction : 746/891, Cost : 0.3714339065163759\n",
      "Epoch 22/500, Prediction : 746/891, Cost : 0.3709498510416911\n",
      "Epoch 23/500, Prediction : 758/891, Cost : 0.376164293683873\n",
      "Epoch 24/500, Prediction : 760/891, Cost : 0.3616250354031521\n",
      "=*=*=*= Loss decreased (0.368783 ===> 0.361625). Saving the model! =*=*=*=\n",
      "Epoch 25/500, Prediction : 752/891, Cost : 0.35424177350286146\n",
      "=*=*=*= Loss decreased (0.361625 ===> 0.354242). Saving the model! =*=*=*=\n",
      "Epoch 26/500, Prediction : 755/891, Cost : 0.3718353770798706\n",
      "Epoch 27/500, Prediction : 751/891, Cost : 0.3671876876108039\n",
      "Epoch 28/500, Prediction : 752/891, Cost : 0.3811851168588623\n",
      "Epoch 29/500, Prediction : 751/891, Cost : 0.354052552570799\n",
      "=*=*=*= Loss decreased (0.354242 ===> 0.354053). Saving the model! =*=*=*=\n",
      "Epoch 30/500, Prediction : 739/891, Cost : 0.3840784448231377\n",
      "Epoch 31/500, Prediction : 740/891, Cost : 0.3646601981720673\n",
      "Epoch 32/500, Prediction : 749/891, Cost : 0.359551156577304\n",
      "Epoch 33/500, Prediction : 760/891, Cost : 0.3574779982251083\n",
      "Epoch 34/500, Prediction : 747/891, Cost : 0.37183410725342037\n",
      "Epoch 35/500, Prediction : 758/891, Cost : 0.3592379620313377\n",
      "Epoch 36/500, Prediction : 749/891, Cost : 0.3506975166257115\n",
      "=*=*=*= Loss decreased (0.354053 ===> 0.350698). Saving the model! =*=*=*=\n",
      "Epoch 37/500, Prediction : 751/891, Cost : 0.36136121905746416\n",
      "Epoch 38/500, Prediction : 752/891, Cost : 0.367262622322699\n",
      "Epoch 39/500, Prediction : 755/891, Cost : 0.3665317402678039\n",
      "Epoch 40/500, Prediction : 749/891, Cost : 0.3604553079631861\n",
      "Epoch 41/500, Prediction : 749/891, Cost : 0.37212293878548874\n",
      "Epoch 42/500, Prediction : 754/891, Cost : 0.3665712467414629\n",
      "Epoch 43/500, Prediction : 757/891, Cost : 0.34643188901621885\n",
      "=*=*=*= Loss decreased (0.350698 ===> 0.346432). Saving the model! =*=*=*=\n",
      "Epoch 44/500, Prediction : 762/891, Cost : 0.3407156220924707\n",
      "=*=*=*= Loss decreased (0.346432 ===> 0.340716). Saving the model! =*=*=*=\n",
      "Epoch 45/500, Prediction : 757/891, Cost : 0.346654560830858\n",
      "Epoch 46/500, Prediction : 757/891, Cost : 0.3415196029224781\n",
      "Epoch 47/500, Prediction : 754/891, Cost : 0.35444239685029694\n",
      "Epoch 48/500, Prediction : 761/891, Cost : 0.3437636977962639\n",
      "Epoch 49/500, Prediction : 764/891, Cost : 0.3592179273783023\n",
      "Epoch 50/500, Prediction : 762/891, Cost : 0.32658302068175155\n",
      "=*=*=*= Loss decreased (0.340716 ===> 0.326583). Saving the model! =*=*=*=\n",
      "Epoch 51/500, Prediction : 764/891, Cost : 0.3502545518305165\n",
      "Epoch 52/500, Prediction : 760/891, Cost : 0.3382416676257462\n",
      "Epoch 53/500, Prediction : 768/891, Cost : 0.3389259463408178\n",
      "Epoch 54/500, Prediction : 762/891, Cost : 0.34054554609203447\n",
      "Epoch 55/500, Prediction : 766/891, Cost : 0.32671493462440543\n",
      "Epoch 56/500, Prediction : 756/891, Cost : 0.33750219872235987\n",
      "Epoch 57/500, Prediction : 766/891, Cost : 0.32989322828122664\n",
      "Epoch 58/500, Prediction : 768/891, Cost : 0.33105743984983427\n",
      "Epoch 59/500, Prediction : 764/891, Cost : 0.32188242509977855\n",
      "=*=*=*= Loss decreased (0.326583 ===> 0.321882). Saving the model! =*=*=*=\n",
      "Epoch 60/500, Prediction : 768/891, Cost : 0.33253142819661485\n",
      "Epoch 61/500, Prediction : 765/891, Cost : 0.3375288459120107\n",
      "Epoch 62/500, Prediction : 764/891, Cost : 0.34073791382823865\n",
      "Epoch 63/500, Prediction : 759/891, Cost : 0.34450563172967613\n",
      "Epoch 64/500, Prediction : 767/891, Cost : 0.34359094748058167\n",
      "Epoch 65/500, Prediction : 764/891, Cost : 0.33076388570328485\n",
      "Epoch 66/500, Prediction : 768/891, Cost : 0.3285820613940289\n",
      "Epoch 67/500, Prediction : 763/891, Cost : 0.3301510715190275\n",
      "Epoch 68/500, Prediction : 762/891, Cost : 0.33753229829866344\n",
      "Epoch 69/500, Prediction : 773/891, Cost : 0.32721778074766517\n",
      "Epoch 70/500, Prediction : 768/891, Cost : 0.32392088383202067\n",
      "Epoch 71/500, Prediction : 768/891, Cost : 0.3231263295167223\n",
      "Epoch 72/500, Prediction : 768/891, Cost : 0.3253183291616665\n",
      "Epoch 73/500, Prediction : 752/891, Cost : 0.33179964036518744\n",
      "Epoch 74/500, Prediction : 771/891, Cost : 0.3154813951983061\n",
      "=*=*=*= Loss decreased (0.321882 ===> 0.315481). Saving the model! =*=*=*=\n",
      "Epoch 75/500, Prediction : 759/891, Cost : 0.3366551991263624\n",
      "Epoch 76/500, Prediction : 767/891, Cost : 0.32504533881825365\n",
      "Epoch 77/500, Prediction : 765/891, Cost : 0.31256303244702077\n",
      "=*=*=*= Loss decreased (0.315481 ===> 0.312563). Saving the model! =*=*=*=\n",
      "Epoch 78/500, Prediction : 773/891, Cost : 0.3529349504630306\n",
      "Epoch 79/500, Prediction : 758/891, Cost : 0.3425763222638739\n",
      "Epoch 80/500, Prediction : 768/891, Cost : 0.3265705202297463\n",
      "Epoch 81/500, Prediction : 771/891, Cost : 0.3421596119098792\n",
      "Epoch 82/500, Prediction : 768/891, Cost : 0.3441638117520229\n",
      "Epoch 83/500, Prediction : 766/891, Cost : 0.34000959102687345\n",
      "Epoch 84/500, Prediction : 762/891, Cost : 0.3419011901859215\n",
      "Epoch 85/500, Prediction : 767/891, Cost : 0.332408429028343\n",
      "Epoch 86/500, Prediction : 777/891, Cost : 0.30852257847518366\n",
      "=*=*=*= Loss decreased (0.312563 ===> 0.308523). Saving the model! =*=*=*=\n",
      "Epoch 87/500, Prediction : 765/891, Cost : 0.3355576652870435\n",
      "Epoch 88/500, Prediction : 774/891, Cost : 0.3176832890804903\n",
      "Epoch 89/500, Prediction : 766/891, Cost : 0.3215937819812702\n",
      "Epoch 90/500, Prediction : 770/891, Cost : 0.31413915489123995\n",
      "Epoch 91/500, Prediction : 758/891, Cost : 0.31342604672734853\n",
      "Epoch 92/500, Prediction : 773/891, Cost : 0.3136715250618664\n",
      "Epoch 93/500, Prediction : 763/891, Cost : 0.321663643274243\n",
      "Epoch 94/500, Prediction : 764/891, Cost : 0.32384019544897924\n",
      "Epoch 95/500, Prediction : 773/891, Cost : 0.3080327190734722\n",
      "=*=*=*= Loss decreased (0.308523 ===> 0.308033). Saving the model! =*=*=*=\n",
      "Epoch 96/500, Prediction : 769/891, Cost : 0.32240814897080194\n",
      "Epoch 97/500, Prediction : 770/891, Cost : 0.3345498437967097\n",
      "Epoch 98/500, Prediction : 771/891, Cost : 0.3115791366189952\n",
      "Epoch 99/500, Prediction : 767/891, Cost : 0.32027531947886234\n",
      "Epoch 100/500, Prediction : 770/891, Cost : 0.3148804693310349\n",
      "Epoch 101/500, Prediction : 778/891, Cost : 0.31985817898135926\n",
      "Epoch 102/500, Prediction : 770/891, Cost : 0.31632639456009354\n",
      "Epoch 103/500, Prediction : 761/891, Cost : 0.32233852328676166\n",
      "Epoch 104/500, Prediction : 772/891, Cost : 0.32378710433422647\n",
      "Epoch 105/500, Prediction : 763/891, Cost : 0.3186276854756973\n",
      "Epoch 106/500, Prediction : 774/891, Cost : 0.3082614549583056\n",
      "Epoch 107/500, Prediction : 771/891, Cost : 0.3117497634272249\n",
      "Epoch 108/500, Prediction : 773/891, Cost : 0.31615462715243114\n",
      "Epoch 109/500, Prediction : 763/891, Cost : 0.3281197512457534\n",
      "Epoch 110/500, Prediction : 771/891, Cost : 0.3110553965758528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500, Prediction : 763/891, Cost : 0.31633163274471743\n",
      "Epoch 112/500, Prediction : 767/891, Cost : 0.31879371672233214\n",
      "Epoch 113/500, Prediction : 770/891, Cost : 0.3298324505755663\n",
      "Epoch 114/500, Prediction : 775/891, Cost : 0.30777121687310044\n",
      "=*=*=*= Loss decreased (0.308033 ===> 0.307771). Saving the model! =*=*=*=\n",
      "Epoch 115/500, Prediction : 767/891, Cost : 0.32078785001897114\n",
      "Epoch 116/500, Prediction : 774/891, Cost : 0.3029871112703608\n",
      "=*=*=*= Loss decreased (0.307771 ===> 0.302987). Saving the model! =*=*=*=\n",
      "Epoch 117/500, Prediction : 766/891, Cost : 0.3039541918822009\n",
      "Epoch 118/500, Prediction : 771/891, Cost : 0.3105379475153121\n",
      "Epoch 119/500, Prediction : 777/891, Cost : 0.32598987609716645\n",
      "Epoch 120/500, Prediction : 775/891, Cost : 0.3021528464308224\n",
      "=*=*=*= Loss decreased (0.302987 ===> 0.302153). Saving the model! =*=*=*=\n",
      "Epoch 121/500, Prediction : 776/891, Cost : 0.29345418492752295\n",
      "=*=*=*= Loss decreased (0.302153 ===> 0.293454). Saving the model! =*=*=*=\n",
      "Epoch 122/500, Prediction : 775/891, Cost : 0.2993791364258789\n",
      "Epoch 123/500, Prediction : 781/891, Cost : 0.2906610308137673\n",
      "=*=*=*= Loss decreased (0.293454 ===> 0.290661). Saving the model! =*=*=*=\n",
      "Epoch 124/500, Prediction : 771/891, Cost : 0.30164486280194036\n",
      "Epoch 125/500, Prediction : 774/891, Cost : 0.29811685710442987\n",
      "Epoch 126/500, Prediction : 768/891, Cost : 0.2945725636182543\n",
      "Epoch 127/500, Prediction : 777/891, Cost : 0.2940229016756503\n",
      "Epoch 128/500, Prediction : 778/891, Cost : 0.2935125053631336\n",
      "Epoch 129/500, Prediction : 768/891, Cost : 0.3102259035196101\n",
      "Epoch 130/500, Prediction : 778/891, Cost : 0.31630221932424035\n",
      "Epoch 131/500, Prediction : 774/891, Cost : 0.29992604349331153\n",
      "Epoch 132/500, Prediction : 762/891, Cost : 0.3200590534911279\n",
      "Epoch 133/500, Prediction : 778/891, Cost : 0.3018049555260993\n",
      "Epoch 134/500, Prediction : 781/891, Cost : 0.29725732797324056\n",
      "Epoch 135/500, Prediction : 773/891, Cost : 0.29932433166086475\n",
      "Epoch 136/500, Prediction : 774/891, Cost : 0.2878586781680517\n",
      "=*=*=*= Loss decreased (0.290661 ===> 0.287859). Saving the model! =*=*=*=\n",
      "Epoch 137/500, Prediction : 769/891, Cost : 0.30954590627106215\n",
      "Epoch 138/500, Prediction : 772/891, Cost : 0.30484425424526035\n",
      "Epoch 139/500, Prediction : 769/891, Cost : 0.29991615052710213\n",
      "Epoch 140/500, Prediction : 775/891, Cost : 0.29617261317977733\n",
      "Epoch 141/500, Prediction : 775/891, Cost : 0.30845284104079645\n",
      "Epoch 142/500, Prediction : 778/891, Cost : 0.29715520253887884\n",
      "Epoch 143/500, Prediction : 773/891, Cost : 0.32292799576364384\n",
      "Epoch 144/500, Prediction : 774/891, Cost : 0.2983333883696266\n",
      "Epoch 145/500, Prediction : 767/891, Cost : 0.3128181210605116\n",
      "Epoch 146/500, Prediction : 766/891, Cost : 0.30888141225082705\n",
      "Epoch 147/500, Prediction : 771/891, Cost : 0.295200742722628\n",
      "Epoch 148/500, Prediction : 768/891, Cost : 0.31150505498603537\n",
      "Epoch 149/500, Prediction : 776/891, Cost : 0.302748902478202\n",
      "Epoch 150/500, Prediction : 768/891, Cost : 0.30763392530038836\n",
      "Epoch 151/500, Prediction : 779/891, Cost : 0.289066169799779\n",
      "Epoch 152/500, Prediction : 771/891, Cost : 0.29345404013038084\n",
      "Epoch 153/500, Prediction : 773/891, Cost : 0.3011964732816591\n",
      "Epoch 154/500, Prediction : 778/891, Cost : 0.3120888009349639\n",
      "Epoch 155/500, Prediction : 771/891, Cost : 0.29674318606738426\n",
      "Epoch 156/500, Prediction : 777/891, Cost : 0.290306144056363\n",
      "Epoch 157/500, Prediction : 775/891, Cost : 0.28918245287589084\n",
      "Epoch 158/500, Prediction : 771/891, Cost : 0.3075448070411329\n",
      "Epoch 159/500, Prediction : 774/891, Cost : 0.2906102484257267\n",
      "Epoch 160/500, Prediction : 782/891, Cost : 0.29498722958645035\n",
      "Epoch 161/500, Prediction : 774/891, Cost : 0.2929411078609869\n",
      "Epoch 162/500, Prediction : 775/891, Cost : 0.29289413923366303\n",
      "Epoch 163/500, Prediction : 780/891, Cost : 0.2824037256331824\n",
      "=*=*=*= Loss decreased (0.287859 ===> 0.282404). Saving the model! =*=*=*=\n",
      "Epoch 164/500, Prediction : 780/891, Cost : 0.2871677312251561\n",
      "Epoch 165/500, Prediction : 779/891, Cost : 0.3011743789235617\n",
      "Epoch 166/500, Prediction : 772/891, Cost : 0.28580428216727627\n",
      "Epoch 167/500, Prediction : 777/891, Cost : 0.281737824916572\n",
      "=*=*=*= Loss decreased (0.282404 ===> 0.281738). Saving the model! =*=*=*=\n",
      "Epoch 168/500, Prediction : 781/891, Cost : 0.29536887844470483\n",
      "Epoch 169/500, Prediction : 773/891, Cost : 0.29436625190723087\n",
      "Epoch 170/500, Prediction : 773/891, Cost : 0.2890516065989279\n",
      "Epoch 171/500, Prediction : 775/891, Cost : 0.2887996516946189\n",
      "Epoch 172/500, Prediction : 776/891, Cost : 0.27614687925035303\n",
      "=*=*=*= Loss decreased (0.281738 ===> 0.276147). Saving the model! =*=*=*=\n",
      "Epoch 173/500, Prediction : 781/891, Cost : 0.2822652678899091\n",
      "Epoch 174/500, Prediction : 778/891, Cost : 0.2882543875847334\n",
      "Epoch 175/500, Prediction : 779/891, Cost : 0.2840787317148095\n",
      "Epoch 176/500, Prediction : 781/891, Cost : 0.28596288166463574\n",
      "Epoch 177/500, Prediction : 774/891, Cost : 0.28413276717183833\n",
      "Epoch 178/500, Prediction : 771/891, Cost : 0.2947987402328337\n",
      "Epoch 179/500, Prediction : 776/891, Cost : 0.29913131145114447\n",
      "Epoch 180/500, Prediction : 779/891, Cost : 0.2844179755977776\n",
      "Epoch 181/500, Prediction : 778/891, Cost : 0.2819932972307826\n",
      "Epoch 182/500, Prediction : 781/891, Cost : 0.30144817346140457\n",
      "Epoch 183/500, Prediction : 778/891, Cost : 0.2746289490348964\n",
      "=*=*=*= Loss decreased (0.276147 ===> 0.274629). Saving the model! =*=*=*=\n",
      "Epoch 184/500, Prediction : 774/891, Cost : 0.29622341011777337\n",
      "Epoch 185/500, Prediction : 775/891, Cost : 0.2952733296403446\n",
      "Epoch 186/500, Prediction : 771/891, Cost : 0.29967488955568383\n",
      "Epoch 187/500, Prediction : 766/891, Cost : 0.29777648580060934\n",
      "Epoch 188/500, Prediction : 770/891, Cost : 0.30168680855053176\n",
      "Epoch 189/500, Prediction : 777/891, Cost : 0.2980569307049517\n",
      "Epoch 190/500, Prediction : 773/891, Cost : 0.31623754942189697\n",
      "Epoch 191/500, Prediction : 779/891, Cost : 0.3009574799960444\n",
      "Epoch 192/500, Prediction : 777/891, Cost : 0.2897055198748906\n",
      "Epoch 193/500, Prediction : 775/891, Cost : 0.285258704999213\n",
      "Epoch 194/500, Prediction : 777/891, Cost : 0.2816754503282232\n",
      "Epoch 195/500, Prediction : 780/891, Cost : 0.29584764731853497\n",
      "Epoch 196/500, Prediction : 780/891, Cost : 0.2944854635381538\n",
      "Epoch 197/500, Prediction : 770/891, Cost : 0.28933770267248954\n",
      "Epoch 198/500, Prediction : 774/891, Cost : 0.3062502931464802\n",
      "Epoch 199/500, Prediction : 778/891, Cost : 0.29095377885934076\n",
      "Epoch 200/500, Prediction : 777/891, Cost : 0.29780400565310094\n",
      "Epoch 201/500, Prediction : 779/891, Cost : 0.28088698072064205\n",
      "Epoch 202/500, Prediction : 771/891, Cost : 0.2999453867391571\n",
      "Epoch 203/500, Prediction : 773/891, Cost : 0.28883997636076847\n",
      "Epoch 204/500, Prediction : 773/891, Cost : 0.290695647632768\n",
      "Epoch 205/500, Prediction : 776/891, Cost : 0.29069770872592926\n",
      "Epoch 206/500, Prediction : 767/891, Cost : 0.298342969381448\n",
      "Epoch 207/500, Prediction : 775/891, Cost : 0.2983728033959799\n",
      "Epoch 208/500, Prediction : 771/891, Cost : 0.2968852974215207\n",
      "Epoch 209/500, Prediction : 772/891, Cost : 0.28084100133976686\n",
      "Epoch 210/500, Prediction : 771/891, Cost : 0.2915734510396332\n",
      "Epoch 211/500, Prediction : 774/891, Cost : 0.2832849276253136\n",
      "Epoch 212/500, Prediction : 774/891, Cost : 0.29459083301049693\n",
      "Epoch 213/500, Prediction : 779/891, Cost : 0.31906077372773595\n",
      "Epoch 214/500, Prediction : 766/891, Cost : 0.3159685028856986\n",
      "Epoch 215/500, Prediction : 761/891, Cost : 0.3205152051617401\n",
      "Epoch 216/500, Prediction : 776/891, Cost : 0.31008301606750915\n",
      "Epoch 217/500, Prediction : 773/891, Cost : 0.3056760158904072\n",
      "Epoch 218/500, Prediction : 777/891, Cost : 0.28777499754487734\n",
      "Epoch 219/500, Prediction : 767/891, Cost : 0.3243524591061135\n",
      "Epoch 220/500, Prediction : 769/891, Cost : 0.32351214028100506\n",
      "Epoch 221/500, Prediction : 774/891, Cost : 0.29383372337328467\n",
      "Epoch 222/500, Prediction : 778/891, Cost : 0.284465554704436\n",
      "Epoch 223/500, Prediction : 773/891, Cost : 0.2985665367040302\n",
      "Epoch 224/500, Prediction : 778/891, Cost : 0.28418705457723237\n",
      "Epoch 225/500, Prediction : 781/891, Cost : 0.2885917892761102\n",
      "Epoch 226/500, Prediction : 780/891, Cost : 0.2833296129465371\n",
      "Epoch 227/500, Prediction : 779/891, Cost : 0.2855237221510456\n",
      "Epoch 228/500, Prediction : 781/891, Cost : 0.2792236145698663\n",
      "Epoch 229/500, Prediction : 773/891, Cost : 0.3058061260566968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/500, Prediction : 775/891, Cost : 0.29017101716580485\n",
      "Epoch 231/500, Prediction : 783/891, Cost : 0.28045827817635904\n",
      "Epoch 232/500, Prediction : 775/891, Cost : 0.2698717104264783\n",
      "=*=*=*= Loss decreased (0.274629 ===> 0.269872). Saving the model! =*=*=*=\n",
      "Epoch 233/500, Prediction : 779/891, Cost : 0.2971693451623992\n",
      "Epoch 234/500, Prediction : 777/891, Cost : 0.2943638159436677\n",
      "Epoch 235/500, Prediction : 771/891, Cost : 0.2892109219540918\n",
      "Epoch 236/500, Prediction : 783/891, Cost : 0.29235527146812507\n",
      "Epoch 237/500, Prediction : 774/891, Cost : 0.29073215634734545\n",
      "Epoch 238/500, Prediction : 774/891, Cost : 0.2946560084485312\n",
      "Epoch 239/500, Prediction : 772/891, Cost : 0.2856481707122858\n",
      "Epoch 240/500, Prediction : 780/891, Cost : 0.27833042685966836\n",
      "Epoch 241/500, Prediction : 775/891, Cost : 0.3034653157564392\n",
      "Epoch 242/500, Prediction : 777/891, Cost : 0.2786924294149033\n",
      "Epoch 243/500, Prediction : 782/891, Cost : 0.28518993120669783\n",
      "Epoch 244/500, Prediction : 778/891, Cost : 0.28632128860814\n",
      "Epoch 245/500, Prediction : 780/891, Cost : 0.2772854817769878\n",
      "Epoch 246/500, Prediction : 771/891, Cost : 0.2816597336503927\n",
      "Epoch 247/500, Prediction : 771/891, Cost : 0.2838315529587828\n",
      "Epoch 248/500, Prediction : 773/891, Cost : 0.28379164925461803\n",
      "Epoch 249/500, Prediction : 782/891, Cost : 0.28340674960185114\n",
      "Epoch 250/500, Prediction : 780/891, Cost : 0.2805993871389147\n",
      "Epoch 251/500, Prediction : 777/891, Cost : 0.27987310805438476\n",
      "Epoch 252/500, Prediction : 774/891, Cost : 0.27398959775565046\n",
      "Epoch 253/500, Prediction : 772/891, Cost : 0.2911283416980846\n",
      "Epoch 254/500, Prediction : 774/891, Cost : 0.28825398731044377\n",
      "Epoch 255/500, Prediction : 784/891, Cost : 0.26907926587143327\n",
      "=*=*=*= Loss decreased (0.269872 ===> 0.269079). Saving the model! =*=*=*=\n",
      "Epoch 256/500, Prediction : 777/891, Cost : 0.28144714741326876\n",
      "Epoch 257/500, Prediction : 780/891, Cost : 0.27314631635893877\n",
      "Epoch 258/500, Prediction : 784/891, Cost : 0.26699578869088597\n",
      "=*=*=*= Loss decreased (0.269079 ===> 0.266996). Saving the model! =*=*=*=\n",
      "Epoch 259/500, Prediction : 779/891, Cost : 0.26600237567015367\n",
      "=*=*=*= Loss decreased (0.266996 ===> 0.266002). Saving the model! =*=*=*=\n",
      "Epoch 260/500, Prediction : 780/891, Cost : 0.2673659206072222\n",
      "Epoch 261/500, Prediction : 774/891, Cost : 0.2773009121551792\n",
      "Epoch 262/500, Prediction : 779/891, Cost : 0.2999306450588535\n",
      "Epoch 263/500, Prediction : 768/891, Cost : 0.28771354356732565\n",
      "Epoch 264/500, Prediction : 777/891, Cost : 0.28766381021434345\n",
      "Epoch 265/500, Prediction : 779/891, Cost : 0.2769897020224369\n",
      "Epoch 266/500, Prediction : 783/891, Cost : 0.2768494164702868\n",
      "Epoch 267/500, Prediction : 782/891, Cost : 0.2869730774066531\n",
      "Epoch 268/500, Prediction : 776/891, Cost : 0.27143960249611293\n",
      "Epoch 269/500, Prediction : 776/891, Cost : 0.2963839497764236\n",
      "Epoch 270/500, Prediction : 783/891, Cost : 0.2774558529575532\n",
      "Epoch 271/500, Prediction : 779/891, Cost : 0.27455772914402143\n",
      "Epoch 272/500, Prediction : 782/891, Cost : 0.2750957100981414\n",
      "Epoch 273/500, Prediction : 778/891, Cost : 0.2700113153083022\n",
      "Epoch 274/500, Prediction : 779/891, Cost : 0.28380428033846394\n",
      "Epoch 275/500, Prediction : 782/891, Cost : 0.28267255475625447\n",
      "Epoch 276/500, Prediction : 786/891, Cost : 0.27460707688973807\n",
      "Epoch 277/500, Prediction : 782/891, Cost : 0.2633748666940447\n",
      "=*=*=*= Loss decreased (0.266002 ===> 0.263375). Saving the model! =*=*=*=\n",
      "Epoch 278/500, Prediction : 783/891, Cost : 0.2760477495514584\n",
      "Epoch 279/500, Prediction : 775/891, Cost : 0.27393858457521425\n",
      "Epoch 280/500, Prediction : 784/891, Cost : 0.26209879092094474\n",
      "=*=*=*= Loss decreased (0.263375 ===> 0.262099). Saving the model! =*=*=*=\n",
      "Epoch 281/500, Prediction : 776/891, Cost : 0.28398288587394654\n",
      "Epoch 282/500, Prediction : 787/891, Cost : 0.2570523928880156\n",
      "=*=*=*= Loss decreased (0.262099 ===> 0.257052). Saving the model! =*=*=*=\n",
      "Epoch 283/500, Prediction : 782/891, Cost : 0.26207507880849873\n",
      "Epoch 284/500, Prediction : 780/891, Cost : 0.2795418166585777\n",
      "Epoch 285/500, Prediction : 777/891, Cost : 0.27252217347908236\n",
      "Epoch 286/500, Prediction : 775/891, Cost : 0.280423604913566\n",
      "Epoch 287/500, Prediction : 784/891, Cost : 0.2745385108605512\n",
      "Epoch 288/500, Prediction : 782/891, Cost : 0.2774321161603553\n",
      "Epoch 289/500, Prediction : 777/891, Cost : 0.26801459959527324\n",
      "Epoch 290/500, Prediction : 785/891, Cost : 0.2691025168339144\n",
      "Epoch 291/500, Prediction : 779/891, Cost : 0.29405721001887297\n",
      "Epoch 292/500, Prediction : 772/891, Cost : 0.28015011244617594\n",
      "Epoch 293/500, Prediction : 775/891, Cost : 0.2701127059866416\n",
      "Epoch 294/500, Prediction : 781/891, Cost : 0.27857741054594853\n",
      "Epoch 295/500, Prediction : 786/891, Cost : 0.2659121740078418\n",
      "Epoch 296/500, Prediction : 781/891, Cost : 0.2724150578783016\n",
      "Epoch 297/500, Prediction : 783/891, Cost : 0.28382408271066\n",
      "Epoch 298/500, Prediction : 780/891, Cost : 0.29015627587015513\n",
      "Epoch 299/500, Prediction : 781/891, Cost : 0.28953627909206514\n",
      "Epoch 300/500, Prediction : 771/891, Cost : 0.2878860029173486\n",
      "Epoch 301/500, Prediction : 775/891, Cost : 0.2790074400461616\n",
      "Epoch 302/500, Prediction : 781/891, Cost : 0.27298675144695406\n",
      "Epoch 303/500, Prediction : 778/891, Cost : 0.25705377240775007\n",
      "Epoch 304/500, Prediction : 784/891, Cost : 0.2882195333505988\n",
      "Epoch 305/500, Prediction : 780/891, Cost : 0.2730036367872347\n",
      "Epoch 306/500, Prediction : 779/891, Cost : 0.2785681488471133\n",
      "Epoch 307/500, Prediction : 785/891, Cost : 0.2727538041527959\n",
      "Epoch 308/500, Prediction : 781/891, Cost : 0.281473583678739\n",
      "Epoch 309/500, Prediction : 780/891, Cost : 0.28483421516873353\n",
      "Epoch 310/500, Prediction : 784/891, Cost : 0.272652466857741\n",
      "Epoch 311/500, Prediction : 778/891, Cost : 0.268843596364245\n",
      "Epoch 312/500, Prediction : 780/891, Cost : 0.2796100995155296\n",
      "Epoch 313/500, Prediction : 786/891, Cost : 0.2674888912943745\n",
      "Epoch 314/500, Prediction : 778/891, Cost : 0.27587865321456917\n",
      "Epoch 315/500, Prediction : 778/891, Cost : 0.26090296310206457\n",
      "Epoch 316/500, Prediction : 780/891, Cost : 0.26696343714942034\n",
      "Epoch 317/500, Prediction : 776/891, Cost : 0.2742890257693568\n",
      "Epoch 318/500, Prediction : 784/891, Cost : 0.28295322871368744\n",
      "Epoch 319/500, Prediction : 781/891, Cost : 0.27118277720329337\n",
      "Epoch 320/500, Prediction : 783/891, Cost : 0.27135252400680826\n",
      "Epoch 321/500, Prediction : 778/891, Cost : 0.2795832174695301\n",
      "Epoch 322/500, Prediction : 790/891, Cost : 0.2504542122953535\n",
      "=*=*=*= Loss decreased (0.257052 ===> 0.250454). Saving the model! =*=*=*=\n",
      "Epoch 323/500, Prediction : 784/891, Cost : 0.2682534459932351\n",
      "Epoch 324/500, Prediction : 786/891, Cost : 0.26828466658506595\n",
      "Epoch 325/500, Prediction : 780/891, Cost : 0.2802610500359241\n",
      "Epoch 326/500, Prediction : 789/891, Cost : 0.26649173144272015\n",
      "Epoch 327/500, Prediction : 782/891, Cost : 0.27212649095473196\n",
      "Epoch 328/500, Prediction : 787/891, Cost : 0.2602956873666825\n",
      "Epoch 329/500, Prediction : 779/891, Cost : 0.2684261852041238\n",
      "Epoch 330/500, Prediction : 790/891, Cost : 0.2510930321332983\n",
      "Epoch 331/500, Prediction : 784/891, Cost : 0.29753925128684167\n",
      "Epoch 332/500, Prediction : 784/891, Cost : 0.2729456940149485\n",
      "Epoch 333/500, Prediction : 785/891, Cost : 0.2679645704099225\n",
      "Epoch 334/500, Prediction : 784/891, Cost : 0.26792728991219494\n",
      "Epoch 335/500, Prediction : 781/891, Cost : 0.2722209811913044\n",
      "Epoch 336/500, Prediction : 777/891, Cost : 0.27148986615315834\n",
      "Epoch 337/500, Prediction : 776/891, Cost : 0.26579103151422023\n",
      "Epoch 338/500, Prediction : 789/891, Cost : 0.27090311767878356\n",
      "Epoch 339/500, Prediction : 788/891, Cost : 0.263697088534048\n",
      "Epoch 340/500, Prediction : 780/891, Cost : 0.2808293521103233\n",
      "Epoch 341/500, Prediction : 782/891, Cost : 0.27129797113998705\n",
      "Epoch 342/500, Prediction : 788/891, Cost : 0.26725407622077246\n",
      "Epoch 343/500, Prediction : 785/891, Cost : 0.27052268322335615\n",
      "Epoch 344/500, Prediction : 782/891, Cost : 0.26910062480454494\n",
      "Epoch 345/500, Prediction : 781/891, Cost : 0.28252382153346217\n",
      "Epoch 346/500, Prediction : 780/891, Cost : 0.265702932537873\n",
      "Epoch 347/500, Prediction : 781/891, Cost : 0.26591596846896254\n",
      "Epoch 348/500, Prediction : 789/891, Cost : 0.26231454331197857\n",
      "Epoch 349/500, Prediction : 783/891, Cost : 0.2616328622656639\n",
      "Epoch 350/500, Prediction : 784/891, Cost : 0.2703750159269498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500, Prediction : 785/891, Cost : 0.26417615869229893\n",
      "Epoch 352/500, Prediction : 785/891, Cost : 0.27663574348528913\n",
      "Epoch 353/500, Prediction : 778/891, Cost : 0.27540172915801187\n",
      "Epoch 354/500, Prediction : 780/891, Cost : 0.2731967258332956\n",
      "Epoch 355/500, Prediction : 782/891, Cost : 0.2607677490957391\n",
      "Epoch 356/500, Prediction : 778/891, Cost : 0.27241169223948625\n",
      "Epoch 357/500, Prediction : 788/891, Cost : 0.26414990769626046\n",
      "Epoch 358/500, Prediction : 772/891, Cost : 0.27263484137628213\n",
      "Epoch 359/500, Prediction : 783/891, Cost : 0.26512641306678053\n",
      "Epoch 360/500, Prediction : 777/891, Cost : 0.27295395029514324\n",
      "Epoch 361/500, Prediction : 780/891, Cost : 0.27595078376540966\n",
      "Epoch 362/500, Prediction : 782/891, Cost : 0.2536285545355008\n",
      "Epoch 363/500, Prediction : 774/891, Cost : 0.26597659085803027\n",
      "Epoch 364/500, Prediction : 784/891, Cost : 0.2614773375083568\n",
      "Epoch 365/500, Prediction : 781/891, Cost : 0.299498465275925\n",
      "Epoch 366/500, Prediction : 775/891, Cost : 0.2875563553821893\n",
      "Epoch 367/500, Prediction : 781/891, Cost : 0.27099437297527773\n",
      "Epoch 368/500, Prediction : 786/891, Cost : 0.2698835819190333\n",
      "Epoch 369/500, Prediction : 788/891, Cost : 0.2579069934643211\n",
      "Epoch 370/500, Prediction : 783/891, Cost : 0.2689593294520437\n",
      "Epoch 371/500, Prediction : 787/891, Cost : 0.26787011010946515\n",
      "Epoch 372/500, Prediction : 775/891, Cost : 0.2574872682592283\n",
      "Epoch 373/500, Prediction : 774/891, Cost : 0.2964918049832118\n",
      "Epoch 374/500, Prediction : 779/891, Cost : 0.27598128308083203\n",
      "Epoch 375/500, Prediction : 780/891, Cost : 0.2696515687320101\n",
      "Epoch 376/500, Prediction : 783/891, Cost : 0.2719328284899126\n",
      "Epoch 377/500, Prediction : 782/891, Cost : 0.26518471654416736\n",
      "Epoch 378/500, Prediction : 783/891, Cost : 0.27159352789556673\n",
      "Epoch 379/500, Prediction : 783/891, Cost : 0.25479908439714366\n",
      "Epoch 380/500, Prediction : 774/891, Cost : 0.268879104878097\n",
      "Epoch 381/500, Prediction : 783/891, Cost : 0.2636904010735243\n",
      "Epoch 382/500, Prediction : 784/891, Cost : 0.25964139028965555\n",
      "Epoch 383/500, Prediction : 784/891, Cost : 0.2672525507833821\n",
      "Epoch 384/500, Prediction : 783/891, Cost : 0.26878137003492425\n",
      "Epoch 385/500, Prediction : 780/891, Cost : 0.26633381793394634\n",
      "Epoch 386/500, Prediction : 780/891, Cost : 0.3087303334247116\n",
      "Epoch 387/500, Prediction : 785/891, Cost : 0.2806190758040457\n",
      "Epoch 388/500, Prediction : 785/891, Cost : 0.270673084573446\n",
      "Epoch 389/500, Prediction : 790/891, Cost : 0.2509024199579166\n",
      "Epoch 390/500, Prediction : 783/891, Cost : 0.2737035029865676\n",
      "Epoch 391/500, Prediction : 784/891, Cost : 0.2566002125691886\n",
      "Epoch 392/500, Prediction : 784/891, Cost : 0.26651013897591835\n",
      "Epoch 393/500, Prediction : 786/891, Cost : 0.2760118813192269\n",
      "Epoch 394/500, Prediction : 777/891, Cost : 0.27379784984754524\n",
      "Epoch 395/500, Prediction : 772/891, Cost : 0.29288302982428793\n",
      "Epoch 396/500, Prediction : 774/891, Cost : 0.2834762556584997\n",
      "Epoch 397/500, Prediction : 783/891, Cost : 0.2810090721723876\n",
      "Epoch 398/500, Prediction : 781/891, Cost : 0.270750988914509\n",
      "Epoch 399/500, Prediction : 779/891, Cost : 0.28195058285989344\n",
      "Epoch 400/500, Prediction : 790/891, Cost : 0.26939226163490587\n",
      "Epoch 401/500, Prediction : 790/891, Cost : 0.278917328392884\n",
      "Epoch 402/500, Prediction : 791/891, Cost : 0.2717263007538621\n",
      "Epoch 403/500, Prediction : 781/891, Cost : 0.2666832049085636\n",
      "Epoch 404/500, Prediction : 780/891, Cost : 0.2678709657639098\n",
      "Epoch 405/500, Prediction : 785/891, Cost : 0.26659410425977137\n",
      "Epoch 406/500, Prediction : 779/891, Cost : 0.2681745557839889\n",
      "Epoch 407/500, Prediction : 778/891, Cost : 0.257290123254228\n",
      "Epoch 408/500, Prediction : 784/891, Cost : 0.25740452901816663\n",
      "Epoch 409/500, Prediction : 781/891, Cost : 0.2725879428897776\n",
      "Epoch 410/500, Prediction : 779/891, Cost : 0.26426650710847105\n",
      "Epoch 411/500, Prediction : 779/891, Cost : 0.2635701321625683\n",
      "Epoch 412/500, Prediction : 784/891, Cost : 0.2614166528889627\n",
      "Epoch 413/500, Prediction : 787/891, Cost : 0.2551756278432981\n",
      "Epoch 414/500, Prediction : 780/891, Cost : 0.28376913304815926\n",
      "Epoch 415/500, Prediction : 779/891, Cost : 0.26985399796304477\n",
      "Epoch 416/500, Prediction : 779/891, Cost : 0.27413887531401465\n",
      "Epoch 417/500, Prediction : 786/891, Cost : 0.2669090712913359\n",
      "Epoch 418/500, Prediction : 780/891, Cost : 0.26727411410155655\n",
      "Epoch 419/500, Prediction : 788/891, Cost : 0.26180356832934015\n",
      "Epoch 420/500, Prediction : 786/891, Cost : 0.2591387369783907\n",
      "Epoch 421/500, Prediction : 786/891, Cost : 0.25612108707093495\n",
      "Epoch 422/500, Prediction : 780/891, Cost : 0.2562460872427248\n",
      "Epoch 423/500, Prediction : 786/891, Cost : 0.24605727399773603\n",
      "=*=*=*= Loss decreased (0.250454 ===> 0.246057). Saving the model! =*=*=*=\n",
      "Epoch 424/500, Prediction : 780/891, Cost : 0.24636634655806888\n",
      "Epoch 425/500, Prediction : 783/891, Cost : 0.24989429427317095\n",
      "Epoch 426/500, Prediction : 785/891, Cost : 0.27095297116088013\n",
      "Epoch 427/500, Prediction : 779/891, Cost : 0.2628131764371253\n",
      "Epoch 428/500, Prediction : 779/891, Cost : 0.2509551643656293\n",
      "Epoch 429/500, Prediction : 781/891, Cost : 0.2465246392353349\n",
      "Epoch 430/500, Prediction : 784/891, Cost : 0.25682035777571494\n",
      "Epoch 431/500, Prediction : 785/891, Cost : 0.25615503457526434\n",
      "Epoch 432/500, Prediction : 785/891, Cost : 0.2526046299907629\n",
      "Epoch 433/500, Prediction : 784/891, Cost : 0.249881677087041\n",
      "Epoch 434/500, Prediction : 776/891, Cost : 0.2539667619933718\n",
      "Epoch 435/500, Prediction : 790/891, Cost : 0.25430338882436654\n",
      "Epoch 436/500, Prediction : 784/891, Cost : 0.2603371101196366\n",
      "Epoch 437/500, Prediction : 783/891, Cost : 0.2662855449114852\n",
      "Epoch 438/500, Prediction : 784/891, Cost : 0.2752871808045106\n",
      "Epoch 439/500, Prediction : 787/891, Cost : 0.24084111181841422\n",
      "=*=*=*= Loss decreased (0.246057 ===> 0.240841). Saving the model! =*=*=*=\n",
      "Epoch 440/500, Prediction : 781/891, Cost : 0.25613678204090107\n",
      "Epoch 441/500, Prediction : 786/891, Cost : 0.25856923618835764\n",
      "Epoch 442/500, Prediction : 784/891, Cost : 0.262042007997515\n",
      "Epoch 443/500, Prediction : 782/891, Cost : 0.25251294443369177\n",
      "Epoch 444/500, Prediction : 781/891, Cost : 0.25571718442386515\n",
      "Epoch 445/500, Prediction : 787/891, Cost : 0.2539101644397183\n",
      "Epoch 446/500, Prediction : 791/891, Cost : 0.25122853177029947\n",
      "Epoch 447/500, Prediction : 788/891, Cost : 0.24846868502973307\n",
      "Epoch 448/500, Prediction : 785/891, Cost : 0.2450498546547895\n",
      "Epoch 449/500, Prediction : 787/891, Cost : 0.2467229239199432\n",
      "Epoch 450/500, Prediction : 786/891, Cost : 0.2679599852507096\n",
      "Epoch 451/500, Prediction : 780/891, Cost : 0.2639016256856865\n",
      "Epoch 452/500, Prediction : 783/891, Cost : 0.24677002222583483\n",
      "Epoch 453/500, Prediction : 785/891, Cost : 0.23201108922059288\n",
      "=*=*=*= Loss decreased (0.240841 ===> 0.232011). Saving the model! =*=*=*=\n",
      "Epoch 454/500, Prediction : 782/891, Cost : 0.2519071808567754\n",
      "Epoch 455/500, Prediction : 784/891, Cost : 0.24368221999285064\n",
      "Epoch 456/500, Prediction : 788/891, Cost : 0.24453784622394142\n",
      "Epoch 457/500, Prediction : 773/891, Cost : 0.2708786930366264\n",
      "Epoch 458/500, Prediction : 786/891, Cost : 0.2724883467226585\n",
      "Epoch 459/500, Prediction : 784/891, Cost : 0.2605557135158918\n",
      "Epoch 460/500, Prediction : 782/891, Cost : 0.2552870447453693\n",
      "Epoch 461/500, Prediction : 790/891, Cost : 0.2769059170409619\n",
      "Epoch 462/500, Prediction : 786/891, Cost : 0.26825101337448914\n",
      "Epoch 463/500, Prediction : 788/891, Cost : 0.2569669286075532\n",
      "Epoch 464/500, Prediction : 783/891, Cost : 0.2672162256323796\n",
      "Epoch 465/500, Prediction : 785/891, Cost : 0.2586612817815659\n",
      "Epoch 466/500, Prediction : 785/891, Cost : 0.27100347806976566\n",
      "Epoch 467/500, Prediction : 786/891, Cost : 0.2624548421430534\n",
      "Epoch 468/500, Prediction : 783/891, Cost : 0.25119585226949487\n",
      "Epoch 469/500, Prediction : 789/891, Cost : 0.250608092472877\n",
      "Epoch 470/500, Prediction : 784/891, Cost : 0.2491321715240928\n",
      "Epoch 471/500, Prediction : 783/891, Cost : 0.26409880734988467\n",
      "Epoch 472/500, Prediction : 781/891, Cost : 0.268670989708467\n",
      "Epoch 473/500, Prediction : 787/891, Cost : 0.24531043008990025\n",
      "Epoch 474/500, Prediction : 781/891, Cost : 0.2556702501979875\n",
      "Epoch 475/500, Prediction : 786/891, Cost : 0.24735088726687512\n",
      "Epoch 476/500, Prediction : 785/891, Cost : 0.25353102394359817\n",
      "Epoch 477/500, Prediction : 786/891, Cost : 0.2474888849974214\n",
      "Epoch 478/500, Prediction : 787/891, Cost : 0.2605218102300475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/500, Prediction : 785/891, Cost : 0.2556743707620736\n",
      "Epoch 480/500, Prediction : 780/891, Cost : 0.25109592839389805\n",
      "Epoch 481/500, Prediction : 788/891, Cost : 0.25161180622649915\n",
      "Epoch 482/500, Prediction : 786/891, Cost : 0.2527396034211021\n",
      "Epoch 483/500, Prediction : 783/891, Cost : 0.26368289597240496\n",
      "Epoch 484/500, Prediction : 789/891, Cost : 0.2643385978058131\n",
      "Epoch 485/500, Prediction : 785/891, Cost : 0.26021233869990384\n",
      "Epoch 486/500, Prediction : 788/891, Cost : 0.25333841009573504\n",
      "Epoch 487/500, Prediction : 779/891, Cost : 0.28273230784402287\n",
      "Epoch 488/500, Prediction : 780/891, Cost : 0.3028023509699621\n",
      "Epoch 489/500, Prediction : 785/891, Cost : 0.2868906552877223\n",
      "Epoch 490/500, Prediction : 789/891, Cost : 0.2766621937320958\n",
      "Epoch 491/500, Prediction : 775/891, Cost : 0.29757643478486673\n",
      "Epoch 492/500, Prediction : 784/891, Cost : 0.2652723996593762\n",
      "Epoch 493/500, Prediction : 779/891, Cost : 0.26594118919436777\n",
      "Epoch 494/500, Prediction : 784/891, Cost : 0.2632302902429861\n",
      "Epoch 495/500, Prediction : 781/891, Cost : 0.2703763261420692\n",
      "Epoch 496/500, Prediction : 781/891, Cost : 0.2634232149916198\n",
      "Epoch 497/500, Prediction : 786/891, Cost : 0.25843184055837853\n",
      "Epoch 498/500, Prediction : 783/891, Cost : 0.2568190131424252\n",
      "Epoch 499/500, Prediction : 781/891, Cost : 0.2585490727598552\n",
      "Epoch 500/500, Prediction : 787/891, Cost : 0.2477602295736405\n",
      "Training Ended!\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 500 ##총 500번 반복한다.\n",
    "train_loss_min = np.Inf ##최소 훈련 손실 값을 추적하는 변수로 초기에 무한대로 설정한다.\n",
    "for epoch in range(nb_epochs):\n",
    "    num_right = 0 ##매 학습에서 맞은 갯수를 따진다.\n",
    "    train_loss = 0 ##각 train loss를 나타내기 위해서 나타낸다.\n",
    "    for batch_idx, samples in enumerate(dataloader): ##dataloader에서 미니 배치 단위로 데이터를 가져온다.\n",
    "        x_train, y_train = samples \n",
    "        \n",
    "        prediction = model(x_train) ##모델을 사용하여 입력 데이터의 예측값을 계산한다.\n",
    "        loss = criterion(prediction, y_train.long()) ##cross entropy 손실함수를 이용하여 차이점을 계산한다. long을 이용하여 타겟 레이블을 정수형으로 계산한다.\n",
    "        \n",
    "        optimizer.zero_grad() ##옵티마이저의 그라디언트를 초기화한다.\n",
    "        loss.backward() ##역전파를 사용하여 그라디언트를 계산한다.\n",
    "        optimizer.step() ##모델 파라미터를 학습한다.\n",
    "        \n",
    "        labels = torch.argmax(prediction, dim=1) ##예측확률이 가장 높은 것을 꺼낸다.\n",
    "        num_right += torch.sum(labels == y_train) ##맞은 갯수를 저장한다.\n",
    "        train_loss += loss.item() * len(x_train) ##현재 batch의 loss를 저장한다.\n",
    "\n",
    "#         print('Epoch {}/{}, Batch {}/{}'.format(epoch, nb_epochs, batch_idx, len(dataloader)))\n",
    "        \n",
    "    train_loss = train_loss / len(X_train) ##전체 비율에 대한 평균 손실을 계산한다.\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "    print('Epoch {}/{}, Prediction : {}/{}, Cost : {}'.format(epoch+1, nb_epochs, num_right, len(X_train), train_loss))\n",
    "    if train_loss <= train_loss_min:\n",
    "        print('=*=*=*= Loss decreased ({:6f} ===> {:6f}). Saving the model! =*=*=*='.format(train_loss_min, train_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt') ##모델의 사전 상태를 파일에 저장하여 모델 상태를 저장한다.\n",
    "        train_loss_min = train_loss\n",
    "        \n",
    "print('Training Ended!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "069b85f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.FloatTensor(test_data.iloc[:,1:].values) ##두번째 열부터 모든 열들을 선택하여 파이토치의 텐서로 변환한다.\n",
    "with torch.no_grad(): ##학습을 진행하지 않도록 한다.\n",
    "    result = model(X_test)\n",
    "labels = torch.argmax(result, dim=1) ##결과를 도출한다.\n",
    "survived = labels.numpy() ##numpy형태로 데이터를 저장한다.\n",
    "survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "935c79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': sub_PassengerId, 'Survived': survived}) ##passenger ID와 Suvived을 결합한다.\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8236d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
